{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5272e673-05f5-4100-bf34-0cfd88081721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.stats import pearsonr\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.utils import to_undirected, negative_sampling\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "from torch_geometric.datasets import FB15k_237\n",
    "from torch_geometric.nn import ComplEx, DistMult, RotatE, TransE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb12c874-b712-4899-8fcf-dfa6d59d4a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d3c41f-cef2-458e-99d9-b0b620c32a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw_data/rawdat/IND/quadruple_idx.txt\",sep = '\\t',names=['source', 'relation', 'destination','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "692c7753-48a6-4a7f-894f-6c4002055fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = df[['source','relation','destination']].values\n",
    "triples, indices = np.unique(triples, return_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522ada8b-9700-40e8-a844-55f6af646eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_entities = len(np.unique(df[['source','relation','destination']].values))\n",
    "num_relations = len(np.unique(df[\"relation\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04bcfa05-a915-4781-8486-f425a846c1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6298, 234)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_entities, num_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374bdf03-299c-4092-8710-fa7f6a15f903",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICEWSDataset(Dataset):\n",
    "    def __init__(self, triples):\n",
    "        self.triples = triples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.triples[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f0e2d7c-540c-424d-8676-a35d17e970de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(dataset, batch_size, validation_split=0.2):\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    valid_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "900479f4-62b3-4d57-aad3-fb4ce23a9b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\desai\\anaconda3\\envs\\cuda_test\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "icews_dataset = ICEWSDataset(triples)\n",
    "data_loader = DataLoader(icews_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b8b9cbc-04b8-4e3f-9398-6623e0935f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplExAttentionModel(nn.Module):\n",
    "    def __init__(self, num_entities, num_relations, embedding_dim):\n",
    "        super(ComplExAttentionModel, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # Embeddings for entities and relations (complex embeddings)\n",
    "        self.entity_embeddings_real = nn.Embedding(num_entities, embedding_dim)\n",
    "        self.entity_embeddings_imag = nn.Embedding(num_entities, embedding_dim)\n",
    "        self.relation_embeddings_real = nn.Embedding(num_relations, embedding_dim)\n",
    "        self.relation_embeddings_imag = nn.Embedding(num_relations, embedding_dim)\n",
    "        \n",
    "        # Attention Layer\n",
    "        self.attention_layer = nn.MultiheadAttention(embedding_dim, num_heads=4)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.entity_embeddings_real.weight)\n",
    "        nn.init.xavier_uniform_(self.entity_embeddings_imag.weight)\n",
    "        nn.init.xavier_uniform_(self.relation_embeddings_real.weight)\n",
    "        nn.init.xavier_uniform_(self.relation_embeddings_imag.weight)\n",
    "    \n",
    "    def score(self, head, relation, tail):\n",
    "        # ComplEx scoring function\n",
    "        real_head = self.entity_embeddings_real(head)\n",
    "        imag_head = self.entity_embeddings_imag(head)\n",
    "        real_relation = self.relation_embeddings_real(relation)\n",
    "        imag_relation = self.relation_embeddings_imag(relation)\n",
    "        real_tail = self.entity_embeddings_real(tail)\n",
    "        imag_tail = self.entity_embeddings_imag(tail)\n",
    "        \n",
    "        # ComplEx score computation\n",
    "        score_real = torch.sum(real_head * real_relation * real_tail + imag_head * imag_relation * imag_tail, dim=-1)\n",
    "        score_imag = torch.sum(real_head * imag_relation * imag_tail - imag_head * real_relation * real_tail, dim=-1)\n",
    "        \n",
    "        return score_real + score_imag\n",
    "    \n",
    "    def forward(self, head, relation):\n",
    "        # Get embeddings for head and relation\n",
    "        real_head = self.entity_embeddings_real(head)\n",
    "        imag_head = self.entity_embeddings_imag(head)\n",
    "        real_relation = self.relation_embeddings_real(relation)\n",
    "        imag_relation = self.relation_embeddings_imag(relation)\n",
    "        \n",
    "        # Compute attention over all entity embeddings\n",
    "        entity_real = self.entity_embeddings_real.weight.unsqueeze(1)\n",
    "        entity_imag = self.entity_embeddings_imag.weight.unsqueeze(1)\n",
    "        \n",
    "        query_real = real_head + real_relation\n",
    "        query_imag = imag_head + imag_relation\n",
    "        \n",
    "        query = query_real + query_imag  # Combine real and imaginary for attention input\n",
    "        key = entity_real + entity_imag   # Keys are all entities in the graph\n",
    "        \n",
    "        # Apply attention mechanism\n",
    "        attention_output, attention_weights = self.attention_layer(query.unsqueeze(1), key, key)\n",
    "        \n",
    "        # Use attention output to predict most likely tail (object entity)\n",
    "        scores = torch.matmul(attention_output.squeeze(1), (entity_real + entity_imag).squeeze(1).T)\n",
    "        return scores, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e24613b-2165-496a-a100-fd200599032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_predictions(scores, true_tail):\n",
    "    sorted_scores, sorted_indices = torch.sort(scores, descending=True)\n",
    "    true_rank = (sorted_indices == true_tail).nonzero(as_tuple=True)[0].item() + 1\n",
    "    return true_rank, sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80c6c5a0-a444-41e5-ba16-255fede505d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, k=10):\n",
    "    model.eval()\n",
    "    total_mrr = 0\n",
    "    total_hits_at_k = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            head = batch[:, 0].to(device)\n",
    "            relation = batch[:, 1].to(device)\n",
    "            tail = batch[:, 2].to(device)\n",
    "\n",
    "            scores, _ = model(head, relation)\n",
    "\n",
    "            for i in range(len(tail)):\n",
    "                true_tail = tail[i]\n",
    "                true_rank, sorted_indices = rank_predictions(scores[i], true_tail)\n",
    "                total_mrr += 1.0 / true_rank\n",
    "                if true_tail in sorted_indices[:k]:\n",
    "                    total_hits_at_k += 1\n",
    "                num_samples += 1\n",
    "\n",
    "    mrr = total_mrr / num_samples\n",
    "    hits_at_k = total_hits_at_k / num_samples\n",
    "    return mrr, hits_at_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "679ccaa0-8569-468a-aa0f-2b7a08010ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, criterion, num_epochs=10, k=10):\n",
    "    \"\"\"\n",
    "    Train the model without negative sampling, as per the original function.\n",
    "    After each epoch, evaluates using MRR and Hits@k.\n",
    "    :param model: The knowledge graph model (e.g., ComplExAttentionModel).\n",
    "    :param data_loader: DataLoader containing training data.\n",
    "    :param optimizer: Optimizer for training (e.g., Adam).\n",
    "    :param criterion: Loss function (e.g., CrossEntropyLoss).\n",
    "    :param num_epochs: Number of training epochs.\n",
    "    :param k: Top-K accuracy for Hits@k.\n",
    "    \"\"\"\n",
    "    # Split the data into train and validation sets\n",
    "    train_loader, valid_loader = create_data_loaders(data_loader.dataset, batch_size=data_loader.batch_size)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        # Training loop\n",
    "        for batch in train_loader:\n",
    "            head, relation, tail = batch[:, 0].to(device), batch[:, 1].to(device), batch[:, 2].to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass: Get scores from the model\n",
    "            scores, attention_weights = model(head, relation)\n",
    "\n",
    "            # Compute the loss between predicted scores and true tail entities\n",
    "            loss = criterion(scores, tail)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Evaluation after each epoch\n",
    "        mrr, hits_at_k = evaluate_model(model, valid_loader, k=k)\n",
    "\n",
    "        # Print loss and evaluation metrics for this epoch\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}, MRR: {mrr:.4f}, Hits@{k}: {hits_at_k:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1836872-f580-47d9-bf6c-e3b614a76c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model, data_loader, optimizer, criterion, num_epochs=10, k=10):\n",
    "#     train_loader, valid_loader = create_data_loaders(data_loader.dataset, batch_size=data_loader.batch_size)\n",
    "#     for epoch in range(num_epochs):\n",
    "#         total_loss = 0\n",
    "#         model.train()\n",
    "#         for batch in train_loader:\n",
    "#             head, relation, tail = batch[:, 0].to(device), batch[:, 1].to(device), batch[:, 2].to(device)\n",
    "#             # head, relation, tail = batch[:, 0], batch[:, 1], batch[:, 2]\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "#             scores, attention_weights = model(head, relation)\n",
    "#             loss = criterion(scores, tail)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             total_loss += loss.item()\n",
    "#         mrr, hits_at_k = evaluate_model(model, head, relation, tail, valid_loader, k=k)\n",
    "\n",
    "#         print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}, MRR: {mrr:.4f}, Hits@{k}: {hits_at_k:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc5fc709-4b33-426d-a25b-f1e18c93e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define criterion and optimizer\n",
    "model = ComplExAttentionModel(num_entities=num_entities, num_relations=num_relations, embedding_dim=64).to(device)\n",
    "# model = ComplExAttentionModel(num_entities=num_entities, num_relations=num_relations, embedding_dim=64)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a0ba238-13a1-466c-b8e8-d02f65c3ade2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 17294.2759, MRR: 0.1653, Hits@10: 0.3022\n",
      "Epoch 2/100, Loss: 16192.2226, MRR: 0.1722, Hits@10: 0.3114\n",
      "Epoch 3/100, Loss: 15878.8669, MRR: 0.1745, Hits@10: 0.3158\n",
      "Epoch 4/100, Loss: 15647.5965, MRR: 0.1750, Hits@10: 0.3174\n",
      "Epoch 5/100, Loss: 15437.7540, MRR: 0.1746, Hits@10: 0.3204\n",
      "Epoch 6/100, Loss: 15256.5276, MRR: 0.1760, Hits@10: 0.3191\n",
      "Epoch 7/100, Loss: 15080.4546, MRR: 0.1791, Hits@10: 0.3249\n",
      "Epoch 8/100, Loss: 14920.8007, MRR: 0.1773, Hits@10: 0.3242\n",
      "Epoch 9/100, Loss: 14773.4141, MRR: 0.1741, Hits@10: 0.3194\n",
      "Epoch 10/100, Loss: 14635.3069, MRR: 0.1747, Hits@10: 0.3200\n",
      "Epoch 11/100, Loss: 14504.6017, MRR: 0.1764, Hits@10: 0.3237\n",
      "Epoch 12/100, Loss: 14386.0163, MRR: 0.1752, Hits@10: 0.3210\n",
      "Epoch 13/100, Loss: 14281.5105, MRR: 0.1712, Hits@10: 0.3192\n",
      "Epoch 14/100, Loss: 14177.4842, MRR: 0.1715, Hits@10: 0.3215\n",
      "Epoch 15/100, Loss: 14080.0837, MRR: 0.1700, Hits@10: 0.3165\n",
      "Epoch 16/100, Loss: 13996.0521, MRR: 0.1704, Hits@10: 0.3168\n",
      "Epoch 17/100, Loss: 13907.6050, MRR: 0.1689, Hits@10: 0.3201\n",
      "Epoch 18/100, Loss: 13843.6413, MRR: 0.1729, Hits@10: 0.3205\n",
      "Epoch 19/100, Loss: 13770.2427, MRR: 0.1722, Hits@10: 0.3227\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 39\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, optimizer, criterion, num_epochs, k)\u001b[0m\n\u001b[0;32m     36\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Evaluation after each epoch\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m mrr, hits_at_k \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Print loss and evaluation metrics for this epoch\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, MRR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmrr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Hits@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhits_at_k\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 17\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, data_loader, k)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(tail)):\n\u001b[0;32m     16\u001b[0m     true_tail \u001b[38;5;241m=\u001b[39m tail[i]\n\u001b[1;32m---> 17\u001b[0m     true_rank, sorted_indices \u001b[38;5;241m=\u001b[39m \u001b[43mrank_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_tail\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     total_mrr \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m true_rank\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m true_tail \u001b[38;5;129;01min\u001b[39;00m sorted_indices[:k]:\n",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m, in \u001b[0;36mrank_predictions\u001b[1;34m(scores, true_tail)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrank_predictions\u001b[39m(scores, true_tail):\n\u001b[0;32m      2\u001b[0m     sorted_scores, sorted_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msort(scores, descending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m     true_rank \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43msorted_indices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrue_tail\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mas_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m true_rank, sorted_indices\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train(model, data_loader, optimizer=optimizer, criterion=criterion, num_epochs=100, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa51270f-1e23-494c-998a-7f2592f1a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_map = {}\n",
    "relation_map = {}\n",
    "with open(\"D:\\\\personal-Shreyas\\\\AIRS\\\\data\\\\raw_data\\\\rawdat\\\\IND\\\\entity2id.txt\",'r',encoding='utf-8') as file:\n",
    "    for line in file.readlines():\n",
    "        entity_map[int(line.split(\"\\t\")[1].strip())] = line.split(\"\\t\")[0]\n",
    "\n",
    "with open(\"D:\\\\personal-Shreyas\\\\AIRS\\\\data\\\\raw_data\\\\rawdat\\\\IND\\\\relation2id.txt\",'r',encoding='utf-8') as file:\n",
    "    for line in file.readlines():\n",
    "        relation_map[int(line.split(\"\\t\")[1].strip())] = line.split(\"\\t\")[0]\n",
    "\n",
    "def get_real_facts(triple):\n",
    "    return entity_map[triple[0]],relation_map[triple[1]],entity_map[triple[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280161e1-5304-4aeb-b876-3c3b95d85fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlated_event_triples(model, head, relation, tail, triples, top_k=5):\n",
    "    \"\"\"\n",
    "    Get the correlated event triples for a given fact (head, relation, tail) using attention weights.\n",
    "    :param model: Trained ComplExAttentionModel\n",
    "    :param head: Tensor containing the head entity\n",
    "    :param relation: Tensor containing the relation\n",
    "    :param tail: Tensor containing the true tail entity (optional for prediction)\n",
    "    :param triples: Array of all known triples (head, relation, tail)\n",
    "    :param top_k: Number of top correlated events to return\n",
    "    :return: top_k_event_triples (correlated event triples), correlated_weights (attention weights)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get scores and attention weights for the query (head, relation)\n",
    "        scores, attention_weights = model(head, relation)\n",
    "        \n",
    "        # The attention weights are for entities, but we want to map them back to triples\n",
    "        entity_real = model.entity_embeddings_real.weight.unsqueeze(1)\n",
    "        entity_imag = model.entity_embeddings_imag.weight.unsqueeze(1)\n",
    "\n",
    "        # Combine real and imaginary parts of the entities to form full embeddings\n",
    "        entity_full = entity_real + entity_imag\n",
    "\n",
    "        # Reshape attention weights to align with the entity space\n",
    "        attention_weights = attention_weights.squeeze()  # Remove any singleton dimensions\n",
    "\n",
    "        # Track which triples got the most attention, we will use `torch.topk` to find top-K attention weights\n",
    "        correlated_triples = []\n",
    "        correlated_weights = []\n",
    "\n",
    "        # Loop through the known triples and gather the attention weights associated with the head, relation, and tail\n",
    "        for i, (h, r, t) in enumerate(triples):\n",
    "            attention_head = attention_weights[h]\n",
    "            attention_tail = attention_weights[t]\n",
    "            combined_attention = attention_head + attention_tail  # Combine attention for head and tail\n",
    "            \n",
    "            correlated_triples.append((h, r, t))\n",
    "            correlated_weights.append(combined_attention)\n",
    "\n",
    "        # Convert to tensor for easy processing\n",
    "        correlated_weights = torch.stack(correlated_weights)\n",
    "\n",
    "        # Get the top-K triples with the highest combined attention weights\n",
    "        top_k_weights, top_k_indices = torch.topk(correlated_weights, k=top_k)\n",
    "        top_k_triples = [correlated_triples[idx] for idx in top_k_indices]\n",
    "\n",
    "        actual_tail_attention_weight = attention_weights[tail].item()\n",
    "        print(f\"Attention weight for true tail entity ({tail.item()}): {actual_tail_attention_weight}\")\n",
    "\n",
    "        for i, (triple, weight) in enumerate(zip(top_k_triples, top_k_weights)):\n",
    "            print(f\"Correlated event triple {i+1}: {get_real_facts(triple)}, Attention weight: {weight.item()}\")\n",
    "        \n",
    "        return top_k_triples, top_k_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc558b1-8f2a-4aa2-b594-3faec238634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query with full fact\n",
    "head = torch.tensor([132]).to(device)  # Example head entity\n",
    "relation = torch.tensor([9]).to(device)  # Example relation\n",
    "tail = torch.tensor([1]).to(device)  # Example true tail entity\n",
    "\n",
    "# head = torch.tensor([31])  # Example head entity\n",
    "# relation = torch.tensor([58]) # Example relation\n",
    "# tail = torch.tensor([1])  # Example true tail entity\n",
    "\n",
    "print(f\"Query triple:{get_real_facts((head.item(),relation.item(),tail.item()))}\")\n",
    "# Call the function with the complete fact (head, relation, tail)\n",
    "correlated_event_triples, correlated_weights = get_correlated_event_triples(model, head, relation, tail, triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3347e818-2ebe-49e4-93d3-3cb46adfe33d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
