{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "WYkfjZW4lWOP",
   "metadata": {
    "id": "WYkfjZW4lWOP"
   },
   "outputs": [],
   "source": [
    "# !pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5272e673-05f5-4100-bf34-0cfd88081721",
   "metadata": {
    "id": "5272e673-05f5-4100-bf34-0cfd88081721"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.stats import pearsonr\n",
    "from torch.utils.data import Dataset\n",
    "# from torch_geometric.utils import to_undirected, negative_sampling\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# from torch_geometric.datasets import FB15k_237\n",
    "# from torch_geometric.nn import ComplEx, DistMult, RotatE, TransE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb12c874-b712-4899-8fcf-dfa6d59d4a53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cb12c874-b712-4899-8fcf-dfa6d59d4a53",
    "outputId": "796c66ca-bbc6-47b3-85e8-8e4e3644ca5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24d3c41f-cef2-458e-99d9-b0b620c32a6e",
   "metadata": {
    "id": "24d3c41f-cef2-458e-99d9-b0b620c32a6e"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\personal-Shreyas\\\\AIRS\\\\data\\\\raw_data\\\\rawdat\\\\IND\\\\quadruple_idx.txt\",sep = '\\t',names=['source', 'relation', 'destination','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "692c7753-48a6-4a7f-894f-6c4002055fd3",
   "metadata": {
    "id": "692c7753-48a6-4a7f-894f-6c4002055fd3"
   },
   "outputs": [],
   "source": [
    "triples = df[['source','relation','destination']].values\n",
    "triples, indices = np.unique(triples, return_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "522ada8b-9700-40e8-a844-55f6af646eb7",
   "metadata": {
    "id": "522ada8b-9700-40e8-a844-55f6af646eb7"
   },
   "outputs": [],
   "source": [
    "num_entities = len(np.unique(df[['source','relation','destination']].values))\n",
    "num_relations = len(np.unique(df[\"relation\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04bcfa05-a915-4781-8486-f425a846c1d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04bcfa05-a915-4781-8486-f425a846c1d6",
    "outputId": "77d78097-ec2b-4950-bc47-6a642231b5ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6298, 234)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_entities, num_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "374bdf03-299c-4092-8710-fa7f6a15f903",
   "metadata": {
    "id": "374bdf03-299c-4092-8710-fa7f6a15f903"
   },
   "outputs": [],
   "source": [
    "class ICEWSDataset(Dataset):\n",
    "    def __init__(self, triples):\n",
    "        self.triples = triples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.triples[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f0e2d7c-540c-424d-8676-a35d17e970de",
   "metadata": {
    "id": "7f0e2d7c-540c-424d-8676-a35d17e970de"
   },
   "outputs": [],
   "source": [
    "def create_data_loaders(dataset, batch_size, validation_split=0.2):\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    valid_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "900479f4-62b3-4d57-aad3-fb4ce23a9b10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "900479f4-62b3-4d57-aad3-fb4ce23a9b10",
    "outputId": "e05c811f-e7e5-438f-9462-73d820068e8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\desai\\anaconda3\\envs\\cuda_test\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "icews_dataset = ICEWSDataset(triples)\n",
    "data_loader = DataLoader(icews_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20d105f7-fa55-4fb7-b52a-fa6828d2e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplExAttentionModel(nn.Module):\n",
    "    def __init__(self, num_entities, num_relations, embedding_dim, dropout_rate=0.3):\n",
    "        super(ComplExAttentionModel, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # Embeddings for entities and relations (complex embeddings)\n",
    "        self.entity_embeddings_real = nn.Embedding(num_entities, embedding_dim)\n",
    "        self.entity_embeddings_imag = nn.Embedding(num_entities, embedding_dim)\n",
    "        self.relation_embeddings_real = nn.Embedding(num_relations, embedding_dim)\n",
    "        self.relation_embeddings_imag = nn.Embedding(num_relations, embedding_dim)\n",
    "        self.entity_bn = nn.BatchNorm1d(embedding_dim)\n",
    "        self.relation_bn = nn.BatchNorm1d(embedding_dim)\n",
    "\n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # Attention Layer\n",
    "        self.attention_layer = nn.MultiheadAttention(embedding_dim, num_heads=32)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.entity_embeddings_real.weight)\n",
    "        nn.init.xavier_uniform_(self.entity_embeddings_imag.weight)\n",
    "        nn.init.xavier_uniform_(self.relation_embeddings_real.weight)\n",
    "        nn.init.xavier_uniform_(self.relation_embeddings_imag.weight)\n",
    "\n",
    "    def score(self, head, relation, tail):\n",
    "        # ComplEx scoring function\n",
    "        real_head = self.entity_embeddings_real(head)\n",
    "        imag_head = self.entity_embeddings_imag(head)\n",
    "        real_relation = self.relation_embeddings_real(relation)\n",
    "        imag_relation = self.relation_embeddings_imag(relation)\n",
    "        real_tail = self.entity_embeddings_real(tail)\n",
    "        imag_tail = self.entity_embeddings_imag(tail)\n",
    "\n",
    "        # Apply batch normalization on embeddings\n",
    "        real_head = self.entity_bn(real_head)\n",
    "        imag_head = self.entity_bn(imag_head)\n",
    "        real_relation = self.relation_bn(real_relation)\n",
    "        imag_relation = self.relation_bn(imag_relation)\n",
    "        real_tail = self.entity_bn(real_tail)\n",
    "        imag_tail = self.entity_bn(imag_tail)\n",
    "\n",
    "        # ComplEx score computation\n",
    "        score_real = torch.sum(real_head * real_relation * real_tail + imag_head * imag_relation * imag_tail, dim=-1)\n",
    "        score_imag = torch.sum(real_head * imag_relation * imag_tail - imag_head * real_relation * real_tail, dim=-1)\n",
    "\n",
    "        return score_real + score_imag\n",
    "\n",
    "    def forward(self, head, relation):\n",
    "        # Get embeddings for head and relation\n",
    "        real_head = self.entity_embeddings_real(head)\n",
    "        imag_head = self.entity_embeddings_imag(head)\n",
    "        real_relation = self.relation_embeddings_real(relation)\n",
    "        imag_relation = self.relation_embeddings_imag(relation)\n",
    "\n",
    "        # Apply batch normalization\n",
    "        real_head = self.entity_bn(real_head)\n",
    "        imag_head = self.entity_bn(imag_head)\n",
    "        real_relation = self.relation_bn(real_relation)\n",
    "        imag_relation = self.relation_bn(imag_relation)\n",
    "\n",
    "        # Apply dropout\n",
    "        real_head = self.dropout(real_head)\n",
    "        imag_head = self.dropout(imag_head)\n",
    "        real_relation = self.dropout(real_relation)\n",
    "        imag_relation = self.dropout(imag_relation)\n",
    "\n",
    "        # Compute attention over all entity embeddings\n",
    "        entity_real = self.entity_embeddings_real.weight.unsqueeze(1)\n",
    "        entity_imag = self.entity_embeddings_imag.weight.unsqueeze(1)\n",
    "\n",
    "        query_real = real_head + real_relation\n",
    "        query_imag = imag_head + imag_relation\n",
    "\n",
    "        query = query_real + query_imag  # Combine real and imaginary for attention input\n",
    "        key = entity_real + entity_imag   # Keys are all entities in the graph\n",
    "\n",
    "        # Apply attention mechanism\n",
    "        attention_output, attention_weights = self.attention_layer(query.unsqueeze(1), key, key)\n",
    "\n",
    "        # Use attention output to predict most likely tail (object entity)\n",
    "        scores = torch.matmul(attention_output.squeeze(), (entity_real + entity_imag).squeeze().T)\n",
    "        return scores, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b8b9cbc-04b8-4e3f-9398-6623e0935f99",
   "metadata": {
    "id": "7b8b9cbc-04b8-4e3f-9398-6623e0935f99"
   },
   "outputs": [],
   "source": [
    "# class ComplExAttentionModel(nn.Module):\n",
    "#     def __init__(self, num_entities, num_relations, embedding_dim, dropout_rate=0.3):\n",
    "#         super(ComplExAttentionModel, self).__init__()\n",
    "#         self.embedding_dim = embedding_dim\n",
    "\n",
    "#         # Embeddings for entities and relations (complex embeddings)\n",
    "#         self.entity_embeddings_real = nn.Embedding(num_entities, embedding_dim)\n",
    "#         self.entity_embeddings_imag = nn.Embedding(num_entities, embedding_dim)\n",
    "#         self.relation_embeddings_real = nn.Embedding(num_relations, embedding_dim)\n",
    "#         self.relation_embeddings_imag = nn.Embedding(num_relations, embedding_dim)\n",
    "#         self.entity_bn = nn.BatchNorm1d(embedding_dim)\n",
    "#         self.relation_bn = nn.BatchNorm1d(embedding_dim)\n",
    "\n",
    "#         # Dropout for regularization\n",
    "#         self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "#         # Attention Layer\n",
    "#         self.attention_layer = nn.MultiheadAttention(embedding_dim, num_heads=32)\n",
    "\n",
    "#         self.init_weights()\n",
    "\n",
    "#     def init_weights(self):\n",
    "#         nn.init.xavier_uniform_(self.entity_embeddings_real.weight)\n",
    "#         nn.init.xavier_uniform_(self.entity_embeddings_imag.weight)\n",
    "#         nn.init.xavier_uniform_(self.relation_embeddings_real.weight)\n",
    "#         nn.init.xavier_uniform_(self.relation_embeddings_imag.weight)\n",
    "\n",
    "#     def score(self, head, relation, tail):\n",
    "#         # ComplEx scoring function\n",
    "#         real_head = self.entity_embeddings_real(head)\n",
    "#         imag_head = self.entity_embeddings_imag(head)\n",
    "#         real_relation = self.relation_embeddings_real(relation)\n",
    "#         imag_relation = self.relation_embeddings_imag(relation)\n",
    "#         real_tail = self.entity_embeddings_real(tail)\n",
    "#         imag_tail = self.entity_embeddings_imag(tail)\n",
    "\n",
    "#         # Apply batch normalization on embeddings\n",
    "#         real_head = self.entity_bn(real_head)\n",
    "#         imag_head = self.entity_bn(imag_head)\n",
    "#         real_relation = self.relation_bn(real_relation)\n",
    "#         imag_relation = self.relation_bn(imag_relation)\n",
    "#         real_tail = self.entity_bn(real_tail)\n",
    "#         imag_tail = self.entity_bn(imag_tail)\n",
    "\n",
    "#         # ComplEx score computation\n",
    "#         score_real = torch.sum(real_head * real_relation * real_tail + imag_head * imag_relation * imag_tail, dim=-1)\n",
    "#         score_imag = torch.sum(real_head * imag_relation * imag_tail - imag_head * real_relation * real_tail, dim=-1)\n",
    "\n",
    "#         return score_real + score_imag\n",
    "\n",
    "#     def forward(self, head, relation):\n",
    "#         # Get embeddings for head and relation\n",
    "#         real_head = self.entity_embeddings_real(head)\n",
    "#         imag_head = self.entity_embeddings_imag(head)\n",
    "#         real_relation = self.relation_embeddings_real(relation)\n",
    "#         imag_relation = self.relation_embeddings_imag(relation)\n",
    "\n",
    "#         # Apply batch normalization\n",
    "#         real_head = self.entity_bn(real_head)\n",
    "#         imag_head = self.entity_bn(imag_head)\n",
    "#         real_relation = self.relation_bn(real_relation)\n",
    "#         imag_relation = self.relation_bn(imag_relation)\n",
    "\n",
    "#         # Apply dropout\n",
    "#         real_head = self.dropout(real_head)\n",
    "#         imag_head = self.dropout(imag_head)\n",
    "#         real_relation = self.dropout(real_relation)\n",
    "#         imag_relation = self.dropout(imag_relation)\n",
    "\n",
    "#         # Compute attention over all entity embeddings\n",
    "#         entity_real = self.entity_embeddings_real.weight.unsqueeze(1)\n",
    "#         entity_imag = self.entity_embeddings_imag.weight.unsqueeze(1)\n",
    "\n",
    "#         query_real = real_head + real_relation\n",
    "#         query_imag = imag_head + imag_relation\n",
    "\n",
    "#         query = query_real + query_imag  # Combine real and imaginary for attention input\n",
    "#         key = entity_real + entity_imag   # Keys are all entities in the graph\n",
    "\n",
    "#         # Apply attention mechanism\n",
    "#         attention_output, attention_weights = self.attention_layer(query.unsqueeze(1), key, key)\n",
    "\n",
    "#         # Use attention output to predict most likely tail (object entity)\n",
    "#         scores = torch.matmul(attention_output.squeeze(1), (entity_real + entity_imag).squeeze(1).T)\n",
    "#         return scores, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e24613b-2165-496a-a100-fd200599032c",
   "metadata": {
    "id": "0e24613b-2165-496a-a100-fd200599032c"
   },
   "outputs": [],
   "source": [
    "def rank_predictions(scores, true_tail):\n",
    "    sorted_scores, sorted_indices = torch.sort(scores, descending=True)\n",
    "    true_rank = (sorted_indices == true_tail).nonzero(as_tuple=True)[0].item() + 1\n",
    "    return true_rank, sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80c6c5a0-a444-41e5-ba16-255fede505d1",
   "metadata": {
    "id": "80c6c5a0-a444-41e5-ba16-255fede505d1"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, k=10):\n",
    "    model.eval()\n",
    "    total_mrr = 0\n",
    "    total_hits_at_k = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            head = batch[:, 0].to(device)\n",
    "            relation = batch[:, 1].to(device)\n",
    "            tail = batch[:, 2].to(device)\n",
    "\n",
    "            scores, _ = model(head, relation)\n",
    "\n",
    "            for i in range(len(tail)):\n",
    "                true_tail = tail[i]\n",
    "                true_rank, sorted_indices = rank_predictions(scores[i], true_tail)\n",
    "                total_mrr += 1.0 / true_rank\n",
    "                if true_tail in sorted_indices[:k]:\n",
    "                    total_hits_at_k += 1\n",
    "                num_samples += 1\n",
    "\n",
    "    mrr = total_mrr / num_samples\n",
    "    hits_at_k = total_hits_at_k / num_samples\n",
    "    return mrr, hits_at_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tXh7OtHrYykQ",
   "metadata": {
    "id": "tXh7OtHrYykQ"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_negative_samples(batch, num_entities):\n",
    "    \"\"\"\n",
    "    Generate negative samples by corrupting either the head or the tail of each triple.\n",
    "\n",
    "    :param batch: A batch of triples (h, r, t)\n",
    "    :param num_entities: Total number of entities in the knowledge graph\n",
    "    :return: Negative samples (same size as the batch)\n",
    "    \"\"\"\n",
    "    negative_batch = batch.clone()\n",
    "\n",
    "    # Randomly corrupt head or tail for each triple\n",
    "    for i in range(batch.size(0)):\n",
    "        corrupt_head = random.choice([True, False])\n",
    "        if corrupt_head:\n",
    "            # Replace the head entity with a random entity\n",
    "            negative_batch[i, 0] = random.randint(0, num_entities - 1)\n",
    "        else:\n",
    "            # Replace the tail entity with a random entity\n",
    "            negative_batch[i, 2] = random.randint(0, num_entities - 1)\n",
    "\n",
    "    return negative_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "679ccaa0-8569-468a-aa0f-2b7a08010ae9",
   "metadata": {
    "id": "679ccaa0-8569-468a-aa0f-2b7a08010ae9"
   },
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, criterion, num_epochs=30, k=10, weight_decay=1e-5, lr_scheduler_step=10, lr_decay_factor=0.5):\n",
    "    \"\"\"\n",
    "    Train the model with learning rate scheduling and weight decay.\n",
    "    :param model: The knowledge graph model (e.g., ComplExAttentionModel).\n",
    "    :param data_loader: DataLoader containing training data.\n",
    "    :param optimizer: Optimizer for training (e.g., Adam).\n",
    "    :param criterion: Loss function (e.g., CrossEntropyLoss).\n",
    "    :param num_epochs: Number of training epochs.\n",
    "    :param k: Top-K accuracy for Hits@k.\n",
    "    :param weight_decay: L2 regularization term.\n",
    "    :param lr_scheduler_step: Number of epochs after which to decay the learning rate.\n",
    "    :param lr_decay_factor: Factor by which to reduce the learning rate.\n",
    "    \"\"\"\n",
    "    # Split the data into train and validation sets\n",
    "    train_loader, valid_loader = create_data_loaders(data_loader.dataset, batch_size=data_loader.batch_size)\n",
    "\n",
    "    # Initialize learning rate scheduler\n",
    "    scheduler = StepLR(optimizer, step_size=lr_scheduler_step, gamma=lr_decay_factor)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        # Training loop\n",
    "        for batch in train_loader:\n",
    "            head, relation, tail = batch[:, 0].to(device), batch[:, 1].to(device), batch[:, 2].to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass: Get scores from the model\n",
    "            scores, attention_weights = model(head, relation)\n",
    "\n",
    "            # Compute the loss between predicted scores and true tail entities\n",
    "            loss = criterion(scores, tail)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Step the scheduler to adjust learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        # Evaluation after each epoch\n",
    "        mrr, hits_at_k = evaluate_model(model, valid_loader, k=k)\n",
    "\n",
    "        # Print loss and evaluation metrics for this epoch\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}, MRR: {mrr:.4f}, Hits@{k}: {hits_at_k:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1836872-f580-47d9-bf6c-e3b614a76c50",
   "metadata": {
    "id": "a1836872-f580-47d9-bf6c-e3b614a76c50"
   },
   "outputs": [],
   "source": [
    "# def train(model, data_loader, optimizer, criterion, num_epochs=10, k=10):\n",
    "#     train_loader, valid_loader = create_data_loaders(data_loader.dataset, batch_size=data_loader.batch_size)\n",
    "#     for epoch in range(num_epochs):\n",
    "#         total_loss = 0\n",
    "#         model.train()\n",
    "#         for batch in train_loader:\n",
    "#             head, relation, tail = batch[:, 0].to(device), batch[:, 1].to(device), batch[:, 2].to(device)\n",
    "#             # head, relation, tail = batch[:, 0], batch[:, 1], batch[:, 2]\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             scores, attention_weights = model(head, relation)\n",
    "#             loss = criterion(scores, tail)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             total_loss += loss.item()\n",
    "#         mrr, hits_at_k = evaluate_model(model, head, relation, tail, valid_loader, k=k)\n",
    "\n",
    "#         print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}, MRR: {mrr:.4f}, Hits@{k}: {hits_at_k:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc5fc709-4b33-426d-a25b-f1e18c93e603",
   "metadata": {
    "id": "dc5fc709-4b33-426d-a25b-f1e18c93e603"
   },
   "outputs": [],
   "source": [
    "# Define criterion and optimizer\n",
    "model = ComplExAttentionModel(num_entities=num_entities, num_relations=num_relations, embedding_dim=512).to(device)\n",
    "# model = ComplExAttentionModel(num_entities=num_entities, num_relations=num_relations, embedding_dim=64)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0ba238-13a1-466c-b8e8-d02f65c3ade2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a0ba238-13a1-466c-b8e8-d02f65c3ade2",
    "outputId": "afdabfc2-ea95-49f2-97f7-97d1728bbcd0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Loss: 18881.3037, MRR: 0.1487, Hits@10: 0.2839\n",
      "Epoch 2/1000, Loss: 17304.5694, MRR: 0.1487, Hits@10: 0.2839\n",
      "Epoch 3/1000, Loss: 17248.9175, MRR: 0.1488, Hits@10: 0.2839\n",
      "Epoch 4/1000, Loss: 17205.0616, MRR: 0.1487, Hits@10: 0.2839\n",
      "Epoch 5/1000, Loss: 17167.1750, MRR: 0.1487, Hits@10: 0.2830\n",
      "Epoch 6/1000, Loss: 17125.5735, MRR: 0.1498, Hits@10: 0.2846\n",
      "Epoch 7/1000, Loss: 17061.6185, MRR: 0.1521, Hits@10: 0.2848\n",
      "Epoch 8/1000, Loss: 16989.4517, MRR: 0.1534, Hits@10: 0.2854\n",
      "Epoch 9/1000, Loss: 16923.5227, MRR: 0.1554, Hits@10: 0.2863\n",
      "Epoch 10/1000, Loss: 16867.2587, MRR: 0.1587, Hits@10: 0.2878\n",
      "Epoch 11/1000, Loss: 16806.9059, MRR: 0.1606, Hits@10: 0.2884\n",
      "Epoch 12/1000, Loss: 16769.2291, MRR: 0.1613, Hits@10: 0.2890\n",
      "Epoch 13/1000, Loss: 16724.4708, MRR: 0.1629, Hits@10: 0.2912\n",
      "Epoch 14/1000, Loss: 16674.9871, MRR: 0.1642, Hits@10: 0.2930\n",
      "Epoch 15/1000, Loss: 16622.0657, MRR: 0.1662, Hits@10: 0.2955\n",
      "Epoch 16/1000, Loss: 16567.9599, MRR: 0.1675, Hits@10: 0.2981\n",
      "Epoch 17/1000, Loss: 16509.3909, MRR: 0.1686, Hits@10: 0.2998\n",
      "Epoch 18/1000, Loss: 16461.2166, MRR: 0.1694, Hits@10: 0.3016\n",
      "Epoch 19/1000, Loss: 16413.4868, MRR: 0.1699, Hits@10: 0.3034\n",
      "Epoch 20/1000, Loss: 16365.7376, MRR: 0.1707, Hits@10: 0.3052\n",
      "Epoch 21/1000, Loss: 16322.0736, MRR: 0.1706, Hits@10: 0.3048\n",
      "Epoch 22/1000, Loss: 16301.8602, MRR: 0.1707, Hits@10: 0.3065\n",
      "Epoch 23/1000, Loss: 16282.1527, MRR: 0.1713, Hits@10: 0.3074\n",
      "Epoch 24/1000, Loss: 16259.1211, MRR: 0.1713, Hits@10: 0.3082\n",
      "Epoch 25/1000, Loss: 16239.9581, MRR: 0.1716, Hits@10: 0.3084\n",
      "Epoch 26/1000, Loss: 16223.8729, MRR: 0.1716, Hits@10: 0.3084\n",
      "Epoch 27/1000, Loss: 16203.8802, MRR: 0.1718, Hits@10: 0.3090\n",
      "Epoch 28/1000, Loss: 16186.3950, MRR: 0.1729, Hits@10: 0.3103\n",
      "Epoch 29/1000, Loss: 16167.8228, MRR: 0.1721, Hits@10: 0.3103\n",
      "Epoch 30/1000, Loss: 16155.1461, MRR: 0.1735, Hits@10: 0.3105\n",
      "Epoch 31/1000, Loss: 16128.5608, MRR: 0.1732, Hits@10: 0.3110\n",
      "Epoch 32/1000, Loss: 16122.0639, MRR: 0.1727, Hits@10: 0.3111\n",
      "Epoch 33/1000, Loss: 16108.1558, MRR: 0.1733, Hits@10: 0.3122\n",
      "Epoch 34/1000, Loss: 16094.9157, MRR: 0.1736, Hits@10: 0.3120\n",
      "Epoch 35/1000, Loss: 16092.0843, MRR: 0.1739, Hits@10: 0.3124\n",
      "Epoch 36/1000, Loss: 16079.2663, MRR: 0.1732, Hits@10: 0.3118\n",
      "Epoch 37/1000, Loss: 16073.4353, MRR: 0.1737, Hits@10: 0.3121\n",
      "Epoch 38/1000, Loss: 16066.7824, MRR: 0.1740, Hits@10: 0.3127\n",
      "Epoch 39/1000, Loss: 16062.0203, MRR: 0.1737, Hits@10: 0.3124\n",
      "Epoch 40/1000, Loss: 16048.8955, MRR: 0.1747, Hits@10: 0.3138\n",
      "Epoch 41/1000, Loss: 16036.5650, MRR: 0.1748, Hits@10: 0.3139\n",
      "Epoch 42/1000, Loss: 16035.7776, MRR: 0.1748, Hits@10: 0.3137\n",
      "Epoch 43/1000, Loss: 16029.7833, MRR: 0.1747, Hits@10: 0.3134\n",
      "Epoch 44/1000, Loss: 16028.9153, MRR: 0.1743, Hits@10: 0.3127\n",
      "Epoch 45/1000, Loss: 16018.6869, MRR: 0.1747, Hits@10: 0.3129\n",
      "Epoch 46/1000, Loss: 16013.7043, MRR: 0.1746, Hits@10: 0.3136\n",
      "Epoch 47/1000, Loss: 16007.6313, MRR: 0.1750, Hits@10: 0.3138\n",
      "Epoch 48/1000, Loss: 15999.0851, MRR: 0.1752, Hits@10: 0.3130\n",
      "Epoch 49/1000, Loss: 16001.3995, MRR: 0.1753, Hits@10: 0.3133\n",
      "Epoch 50/1000, Loss: 15998.3697, MRR: 0.1755, Hits@10: 0.3138\n",
      "Epoch 51/1000, Loss: 15992.4946, MRR: 0.1747, Hits@10: 0.3132\n",
      "Epoch 52/1000, Loss: 15985.8843, MRR: 0.1756, Hits@10: 0.3142\n",
      "Epoch 53/1000, Loss: 15986.2458, MRR: 0.1752, Hits@10: 0.3144\n",
      "Epoch 54/1000, Loss: 15982.6990, MRR: 0.1756, Hits@10: 0.3139\n",
      "Epoch 55/1000, Loss: 15983.6664, MRR: 0.1761, Hits@10: 0.3134\n",
      "Epoch 56/1000, Loss: 15981.7759, MRR: 0.1755, Hits@10: 0.3131\n",
      "Epoch 57/1000, Loss: 15975.2953, MRR: 0.1761, Hits@10: 0.3139\n",
      "Epoch 58/1000, Loss: 15972.4033, MRR: 0.1755, Hits@10: 0.3132\n",
      "Epoch 59/1000, Loss: 15969.1211, MRR: 0.1758, Hits@10: 0.3132\n",
      "Epoch 60/1000, Loss: 15970.4847, MRR: 0.1760, Hits@10: 0.3152\n",
      "Epoch 61/1000, Loss: 15967.9299, MRR: 0.1764, Hits@10: 0.3136\n",
      "Epoch 62/1000, Loss: 15970.3760, MRR: 0.1760, Hits@10: 0.3151\n",
      "Epoch 63/1000, Loss: 15963.5551, MRR: 0.1758, Hits@10: 0.3136\n",
      "Epoch 64/1000, Loss: 15960.9794, MRR: 0.1754, Hits@10: 0.3136\n",
      "Epoch 65/1000, Loss: 15959.4451, MRR: 0.1758, Hits@10: 0.3137\n",
      "Epoch 66/1000, Loss: 15957.0804, MRR: 0.1763, Hits@10: 0.3135\n",
      "Epoch 67/1000, Loss: 15960.2404, MRR: 0.1759, Hits@10: 0.3142\n",
      "Epoch 68/1000, Loss: 15964.0247, MRR: 0.1764, Hits@10: 0.3142\n",
      "Epoch 69/1000, Loss: 15960.3316, MRR: 0.1758, Hits@10: 0.3138\n",
      "Epoch 70/1000, Loss: 15961.8588, MRR: 0.1764, Hits@10: 0.3142\n",
      "Epoch 71/1000, Loss: 15952.9450, MRR: 0.1768, Hits@10: 0.3138\n",
      "Epoch 72/1000, Loss: 15958.5014, MRR: 0.1764, Hits@10: 0.3140\n",
      "Epoch 73/1000, Loss: 15952.7676, MRR: 0.1767, Hits@10: 0.3145\n",
      "Epoch 74/1000, Loss: 15956.0899, MRR: 0.1760, Hits@10: 0.3144\n",
      "Epoch 75/1000, Loss: 15959.4702, MRR: 0.1759, Hits@10: 0.3136\n",
      "Epoch 76/1000, Loss: 15954.4087, MRR: 0.1766, Hits@10: 0.3142\n",
      "Epoch 77/1000, Loss: 15951.0890, MRR: 0.1765, Hits@10: 0.3139\n",
      "Epoch 78/1000, Loss: 15949.7638, MRR: 0.1764, Hits@10: 0.3139\n",
      "Epoch 79/1000, Loss: 15951.4805, MRR: 0.1766, Hits@10: 0.3141\n",
      "Epoch 80/1000, Loss: 15948.6945, MRR: 0.1762, Hits@10: 0.3141\n",
      "Epoch 81/1000, Loss: 15948.8297, MRR: 0.1765, Hits@10: 0.3144\n",
      "Epoch 82/1000, Loss: 15946.6101, MRR: 0.1760, Hits@10: 0.3145\n",
      "Epoch 83/1000, Loss: 15951.1411, MRR: 0.1766, Hits@10: 0.3139\n",
      "Epoch 84/1000, Loss: 15951.7108, MRR: 0.1762, Hits@10: 0.3142\n",
      "Epoch 85/1000, Loss: 15950.1449, MRR: 0.1762, Hits@10: 0.3134\n",
      "Epoch 86/1000, Loss: 15949.9979, MRR: 0.1762, Hits@10: 0.3142\n",
      "Epoch 87/1000, Loss: 15952.0530, MRR: 0.1763, Hits@10: 0.3137\n",
      "Epoch 88/1000, Loss: 15946.1257, MRR: 0.1764, Hits@10: 0.3137\n",
      "Epoch 89/1000, Loss: 15943.4476, MRR: 0.1763, Hits@10: 0.3142\n",
      "Epoch 90/1000, Loss: 15947.3219, MRR: 0.1759, Hits@10: 0.3142\n",
      "Epoch 91/1000, Loss: 15949.1482, MRR: 0.1767, Hits@10: 0.3139\n",
      "Epoch 92/1000, Loss: 15950.3077, MRR: 0.1767, Hits@10: 0.3144\n",
      "Epoch 93/1000, Loss: 15946.7483, MRR: 0.1762, Hits@10: 0.3144\n",
      "Epoch 94/1000, Loss: 15946.0954, MRR: 0.1755, Hits@10: 0.3140\n",
      "Epoch 95/1000, Loss: 15948.6532, MRR: 0.1759, Hits@10: 0.3140\n",
      "Epoch 96/1000, Loss: 15947.5297, MRR: 0.1770, Hits@10: 0.3151\n",
      "Epoch 97/1000, Loss: 15945.1986, MRR: 0.1769, Hits@10: 0.3148\n",
      "Epoch 98/1000, Loss: 15944.5940, MRR: 0.1761, Hits@10: 0.3140\n",
      "Epoch 99/1000, Loss: 15945.6412, MRR: 0.1760, Hits@10: 0.3141\n",
      "Epoch 100/1000, Loss: 15942.9336, MRR: 0.1764, Hits@10: 0.3141\n",
      "Epoch 101/1000, Loss: 15945.7356, MRR: 0.1761, Hits@10: 0.3138\n",
      "Epoch 102/1000, Loss: 15943.3516, MRR: 0.1761, Hits@10: 0.3144\n",
      "Epoch 103/1000, Loss: 15946.9365, MRR: 0.1762, Hits@10: 0.3145\n",
      "Epoch 104/1000, Loss: 15945.9114, MRR: 0.1763, Hits@10: 0.3138\n",
      "Epoch 105/1000, Loss: 15942.8361, MRR: 0.1754, Hits@10: 0.3140\n",
      "Epoch 106/1000, Loss: 15940.8155, MRR: 0.1767, Hits@10: 0.3138\n",
      "Epoch 107/1000, Loss: 15946.9917, MRR: 0.1762, Hits@10: 0.3142\n",
      "Epoch 108/1000, Loss: 15948.6502, MRR: 0.1770, Hits@10: 0.3137\n",
      "Epoch 109/1000, Loss: 15948.6196, MRR: 0.1763, Hits@10: 0.3139\n",
      "Epoch 110/1000, Loss: 15950.5706, MRR: 0.1764, Hits@10: 0.3142\n",
      "Epoch 111/1000, Loss: 15946.1164, MRR: 0.1760, Hits@10: 0.3140\n",
      "Epoch 112/1000, Loss: 15946.5966, MRR: 0.1769, Hits@10: 0.3142\n",
      "Epoch 113/1000, Loss: 15946.8740, MRR: 0.1760, Hits@10: 0.3134\n",
      "Epoch 114/1000, Loss: 15942.7999, MRR: 0.1765, Hits@10: 0.3141\n",
      "Epoch 115/1000, Loss: 15949.1537, MRR: 0.1760, Hits@10: 0.3136\n",
      "Epoch 116/1000, Loss: 15946.1424, MRR: 0.1769, Hits@10: 0.3149\n",
      "Epoch 117/1000, Loss: 15947.4891, MRR: 0.1761, Hits@10: 0.3141\n",
      "Epoch 118/1000, Loss: 15943.8645, MRR: 0.1758, Hits@10: 0.3143\n",
      "Epoch 119/1000, Loss: 15947.5438, MRR: 0.1767, Hits@10: 0.3145\n",
      "Epoch 120/1000, Loss: 15945.6425, MRR: 0.1764, Hits@10: 0.3146\n",
      "Epoch 121/1000, Loss: 15946.1097, MRR: 0.1762, Hits@10: 0.3138\n",
      "Epoch 122/1000, Loss: 15945.5360, MRR: 0.1763, Hits@10: 0.3138\n",
      "Epoch 123/1000, Loss: 15947.2926, MRR: 0.1762, Hits@10: 0.3140\n",
      "Epoch 124/1000, Loss: 15945.1019, MRR: 0.1765, Hits@10: 0.3137\n",
      "Epoch 125/1000, Loss: 15946.9511, MRR: 0.1759, Hits@10: 0.3134\n",
      "Epoch 126/1000, Loss: 15941.9185, MRR: 0.1764, Hits@10: 0.3138\n",
      "Epoch 127/1000, Loss: 15946.7699, MRR: 0.1764, Hits@10: 0.3134\n",
      "Epoch 128/1000, Loss: 15944.4873, MRR: 0.1761, Hits@10: 0.3136\n",
      "Epoch 129/1000, Loss: 15947.7888, MRR: 0.1765, Hits@10: 0.3141\n",
      "Epoch 130/1000, Loss: 15944.6452, MRR: 0.1759, Hits@10: 0.3136\n",
      "Epoch 131/1000, Loss: 15946.1776, MRR: 0.1766, Hits@10: 0.3145\n",
      "Epoch 132/1000, Loss: 15948.0331, MRR: 0.1767, Hits@10: 0.3145\n",
      "Epoch 133/1000, Loss: 15939.5607, MRR: 0.1767, Hits@10: 0.3145\n",
      "Epoch 134/1000, Loss: 15946.6992, MRR: 0.1764, Hits@10: 0.3136\n",
      "Epoch 135/1000, Loss: 15944.5358, MRR: 0.1759, Hits@10: 0.3137\n",
      "Epoch 136/1000, Loss: 15943.6354, MRR: 0.1759, Hits@10: 0.3140\n",
      "Epoch 137/1000, Loss: 15945.9325, MRR: 0.1761, Hits@10: 0.3143\n",
      "Epoch 138/1000, Loss: 15950.0954, MRR: 0.1764, Hits@10: 0.3139\n",
      "Epoch 139/1000, Loss: 15948.2995, MRR: 0.1771, Hits@10: 0.3138\n",
      "Epoch 140/1000, Loss: 15943.4350, MRR: 0.1760, Hits@10: 0.3145\n",
      "Epoch 141/1000, Loss: 15946.3158, MRR: 0.1766, Hits@10: 0.3143\n",
      "Epoch 142/1000, Loss: 15944.7860, MRR: 0.1764, Hits@10: 0.3143\n",
      "Epoch 143/1000, Loss: 15950.3182, MRR: 0.1767, Hits@10: 0.3142\n",
      "Epoch 144/1000, Loss: 15941.6653, MRR: 0.1763, Hits@10: 0.3144\n",
      "Epoch 145/1000, Loss: 15944.1540, MRR: 0.1766, Hits@10: 0.3143\n",
      "Epoch 146/1000, Loss: 15946.8639, MRR: 0.1764, Hits@10: 0.3146\n",
      "Epoch 147/1000, Loss: 15943.2142, MRR: 0.1766, Hits@10: 0.3138\n",
      "Epoch 148/1000, Loss: 15944.5177, MRR: 0.1768, Hits@10: 0.3146\n",
      "Epoch 149/1000, Loss: 15945.6350, MRR: 0.1762, Hits@10: 0.3142\n",
      "Epoch 150/1000, Loss: 15942.7834, MRR: 0.1761, Hits@10: 0.3142\n",
      "Epoch 151/1000, Loss: 15947.7041, MRR: 0.1768, Hits@10: 0.3143\n",
      "Epoch 152/1000, Loss: 15948.3026, MRR: 0.1763, Hits@10: 0.3136\n",
      "Epoch 153/1000, Loss: 15941.5321, MRR: 0.1763, Hits@10: 0.3144\n",
      "Epoch 154/1000, Loss: 15945.7726, MRR: 0.1767, Hits@10: 0.3141\n",
      "Epoch 155/1000, Loss: 15945.6234, MRR: 0.1766, Hits@10: 0.3140\n",
      "Epoch 156/1000, Loss: 15945.9983, MRR: 0.1764, Hits@10: 0.3142\n",
      "Epoch 157/1000, Loss: 15946.1227, MRR: 0.1760, Hits@10: 0.3143\n",
      "Epoch 158/1000, Loss: 15943.2535, MRR: 0.1766, Hits@10: 0.3137\n",
      "Epoch 159/1000, Loss: 15943.1458, MRR: 0.1765, Hits@10: 0.3142\n",
      "Epoch 160/1000, Loss: 15943.8953, MRR: 0.1768, Hits@10: 0.3140\n",
      "Epoch 161/1000, Loss: 15945.3676, MRR: 0.1766, Hits@10: 0.3143\n",
      "Epoch 162/1000, Loss: 15943.5051, MRR: 0.1759, Hits@10: 0.3139\n",
      "Epoch 163/1000, Loss: 15947.3714, MRR: 0.1763, Hits@10: 0.3142\n",
      "Epoch 164/1000, Loss: 15941.7488, MRR: 0.1766, Hits@10: 0.3136\n",
      "Epoch 165/1000, Loss: 15943.3624, MRR: 0.1762, Hits@10: 0.3142\n",
      "Epoch 166/1000, Loss: 15948.2107, MRR: 0.1756, Hits@10: 0.3137\n",
      "Epoch 167/1000, Loss: 15940.2728, MRR: 0.1757, Hits@10: 0.3147\n",
      "Epoch 168/1000, Loss: 15946.3470, MRR: 0.1766, Hits@10: 0.3145\n",
      "Epoch 169/1000, Loss: 15943.1791, MRR: 0.1763, Hits@10: 0.3143\n",
      "Epoch 170/1000, Loss: 15945.2093, MRR: 0.1768, Hits@10: 0.3139\n",
      "Epoch 171/1000, Loss: 15946.4157, MRR: 0.1770, Hits@10: 0.3151\n",
      "Epoch 172/1000, Loss: 15943.5353, MRR: 0.1764, Hits@10: 0.3140\n",
      "Epoch 173/1000, Loss: 15945.6526, MRR: 0.1763, Hits@10: 0.3142\n",
      "Epoch 174/1000, Loss: 15949.4645, MRR: 0.1762, Hits@10: 0.3144\n",
      "Epoch 175/1000, Loss: 15947.4675, MRR: 0.1759, Hits@10: 0.3139\n",
      "Epoch 176/1000, Loss: 15949.3959, MRR: 0.1757, Hits@10: 0.3140\n",
      "Epoch 177/1000, Loss: 15945.7947, MRR: 0.1766, Hits@10: 0.3142\n",
      "Epoch 178/1000, Loss: 15947.4289, MRR: 0.1764, Hits@10: 0.3137\n",
      "Epoch 179/1000, Loss: 15945.9253, MRR: 0.1769, Hits@10: 0.3142\n",
      "Epoch 180/1000, Loss: 15945.3691, MRR: 0.1761, Hits@10: 0.3142\n",
      "Epoch 181/1000, Loss: 15941.2895, MRR: 0.1762, Hits@10: 0.3142\n",
      "Epoch 182/1000, Loss: 15951.3979, MRR: 0.1765, Hits@10: 0.3146\n",
      "Epoch 183/1000, Loss: 15942.8048, MRR: 0.1764, Hits@10: 0.3139\n",
      "Epoch 184/1000, Loss: 15944.2759, MRR: 0.1771, Hits@10: 0.3149\n"
     ]
    }
   ],
   "source": [
    "train(model, data_loader, optimizer, criterion, num_epochs=1000, weight_decay=1e-4, lr_scheduler_step=10, lr_decay_factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa51270f-1e23-494c-998a-7f2592f1a2ed",
   "metadata": {
    "id": "aa51270f-1e23-494c-998a-7f2592f1a2ed"
   },
   "outputs": [],
   "source": [
    "entity_map = {}\n",
    "relation_map = {}\n",
    "with open(\"D:\\\\personal-Shreyas\\\\AIRS\\\\data\\\\raw_data\\\\rawdat\\\\IND\\\\entity2id.txt\",'r',encoding='utf-8') as file:\n",
    "    for line in file.readlines():\n",
    "        entity_map[int(line.split(\"\\t\")[1].strip())] = line.split(\"\\t\")[0]\n",
    "\n",
    "with open(\"D:\\\\personal-Shreyas\\\\AIRS\\\\data\\\\raw_data\\\\rawdat\\\\IND\\\\relation2id.txt\",'r',encoding='utf-8') as file:\n",
    "    for line in file.readlines():\n",
    "        relation_map[int(line.split(\"\\t\")[1].strip())] = line.split(\"\\t\")[0]\n",
    "\n",
    "def get_real_facts(triple):\n",
    "    return entity_map[triple[0]],relation_map[triple[1]],entity_map[triple[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280161e1-5304-4aeb-b876-3c3b95d85fd4",
   "metadata": {
    "id": "280161e1-5304-4aeb-b876-3c3b95d85fd4"
   },
   "outputs": [],
   "source": [
    "def get_correlated_event_triples(model, head, relation, tail, triples, top_k=5):\n",
    "    \"\"\"\n",
    "    Get the correlated event triples for a given fact (head, relation, tail) using attention weights.\n",
    "    :param model: Trained ComplExAttentionModel\n",
    "    :param head: Tensor containing the head entity\n",
    "    :param relation: Tensor containing the relation\n",
    "    :param tail: Tensor containing the true tail entity (optional for prediction)\n",
    "    :param triples: Array of all known triples (head, relation, tail)\n",
    "    :param top_k: Number of top correlated events to return\n",
    "    :return: top_k_event_triples (correlated event triples), correlated_weights (attention weights)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get scores and attention weights for the query (head, relation)\n",
    "        scores, attention_weights = model(head, relation)\n",
    "\n",
    "        # The attention weights are for entities, but we want to map them back to triples\n",
    "        entity_real = model.entity_embeddings_real.weight.unsqueeze(1)\n",
    "        entity_imag = model.entity_embeddings_imag.weight.unsqueeze(1)\n",
    "\n",
    "        # Combine real and imaginary parts of the entities to form full embeddings\n",
    "        entity_full = entity_real + entity_imag\n",
    "\n",
    "        # Reshape attention weights to align with the entity space\n",
    "        attention_weights = attention_weights.squeeze()  # Remove any singleton dimensions\n",
    "\n",
    "        # Track which triples got the most attention, we will use `torch.topk` to find top-K attention weights\n",
    "        correlated_triples = []\n",
    "        correlated_weights = []\n",
    "\n",
    "        # Loop through the known triples and gather the attention weights associated with the head, relation, and tail\n",
    "        for i, (h, r, t) in enumerate(triples):\n",
    "            attention_head = attention_weights[h]\n",
    "            attention_tail = attention_weights[t]\n",
    "            combined_attention = attention_head + attention_tail  # Combine attention for head and tail\n",
    "\n",
    "            correlated_triples.append((h, r, t))\n",
    "            correlated_weights.append(combined_attention)\n",
    "\n",
    "        # Convert to tensor for easy processing\n",
    "        correlated_weights = torch.stack(correlated_weights)\n",
    "\n",
    "        # Get the top-K triples with the highest combined attention weights\n",
    "        top_k_weights, top_k_indices = torch.topk(correlated_weights, k=top_k)\n",
    "        top_k_triples = [correlated_triples[idx] for idx in top_k_indices]\n",
    "\n",
    "        actual_tail_attention_weight = attention_weights[tail].item()\n",
    "        print(f\"Attention weight for true tail entity ({tail.item()}): {actual_tail_attention_weight}\")\n",
    "\n",
    "        for i, (triple, weight) in enumerate(zip(top_k_triples, top_k_weights)):\n",
    "            print(f\"Correlated event triple {i+1}: {get_real_facts(triple)}, Attention weight: {weight.item()}\")\n",
    "\n",
    "        return top_k_triples, top_k_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc558b1-8f2a-4aa2-b594-3faec238634d",
   "metadata": {
    "id": "ccc558b1-8f2a-4aa2-b594-3faec238634d"
   },
   "outputs": [],
   "source": [
    "# Example query with full fact\n",
    "head = torch.tensor([132]).to(device)  # Example head entity\n",
    "relation = torch.tensor([9]).to(device)  # Example relation\n",
    "tail = torch.tensor([1]).to(device)  # Example true tail entity\n",
    "\n",
    "# head = torch.tensor([31])  # Example head entity\n",
    "# relation = torch.tensor([58]) # Example relation\n",
    "# tail = torch.tensor([1])  # Example true tail entity\n",
    "\n",
    "print(f\"Query triple:{get_real_facts((head.item(),relation.item(),tail.item()))}\")\n",
    "correlated_event_triples, correlated_weights = get_correlated_event_triples(model, head, relation, tail, triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3347e818-2ebe-49e4-93d3-3cb46adfe33d",
   "metadata": {
    "id": "3347e818-2ebe-49e4-93d3-3cb46adfe33d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
