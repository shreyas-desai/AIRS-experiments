{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b88955ea-0818-45b7-b400-2e858b00f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "import dgl\n",
    "import dgl.data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.utils import add_self_loops\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea413346-ac86-4bac-8f3b-a2897f33616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"D:\\\\personal-Shreyas\\AIRS\\\\data\\\\raw_data\\\\rawdat\\\\IND\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "195bff4b-314f-4c2a-9a2b-d852d9b75ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GNN model for link prediction\n",
    "class GNNLinkPredictor(nn.Module):\n",
    "    def __init__(self, num_nodes, num_relations, embedding_dim):\n",
    "        super(GNNLinkPredictor, self).__init__()\n",
    "        self.node_embeddings = nn.Embedding(num_nodes, embedding_dim)  # Node embeddings\n",
    "        self.rel_embeddings = nn.Embedding(num_relations, embedding_dim)  # Relation embeddings\n",
    "        \n",
    "        # Graph convolution layers\n",
    "        self.conv1 = GCNConv(embedding_dim, embedding_dim)\n",
    "        self.conv2 = GCNConv(embedding_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, edge_index, source_nodes, rel_types):\n",
    "        # Get initial node embeddings\n",
    "        x = self.node_embeddings.weight\n",
    "        \n",
    "        # Graph Convolution layers\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        # Get source node embeddings and relation embeddings\n",
    "        source_emb = self.node_embeddings(source_nodes)\n",
    "        rel_emb = self.rel_embeddings(rel_types)\n",
    "        \n",
    "        # Calculate target node predictions\n",
    "        combined = source_emb + rel_emb\n",
    "        scores = torch.matmul(combined, self.node_embeddings.weight.t())\n",
    "        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d60109e-92b8-44cd-b023-af171aa892a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Data Generation (this assumes we already have node and relation IDs)\n",
    "def construct_graph(folder_path, train=False):\n",
    "    src, rel, dst, date = [], [], [], []\n",
    "    quadruple_idx_path = folder_path + '/quadruple_idx.txt'\n",
    "    \n",
    "    # Read the quadruples (src, relation, dst, date)\n",
    "    with open(quadruple_idx_path, 'r') as qdrple:\n",
    "        for line in qdrple:\n",
    "            row = line.split()\n",
    "            src.append(row[0])\n",
    "            rel.append(row[1])\n",
    "            dst.append(row[2])\n",
    "            date.append(row[3])\n",
    "    \n",
    "    # Convert data to numpy arrays\n",
    "    if train:\n",
    "        src = np.asarray(src, dtype=\"int64\")[:100000]\n",
    "        dst = np.asarray(dst, dtype=\"int64\")[:100000]\n",
    "        rel = np.asarray(rel, dtype=\"int64\")[:100000]\n",
    "        date = np.asarray(date, dtype=\"int64\")[:100000]\n",
    "    else:\n",
    "        src = np.asarray(src, dtype=\"int64\")[100000:110000]\n",
    "        dst = np.asarray(dst, dtype=\"int64\")[100000:110000]\n",
    "        rel = np.asarray(rel, dtype=\"int64\")[100000:110000]\n",
    "        date = np.asarray(date, dtype=\"int64\")[100000:110000]\n",
    "    # Create edge index for PyTorch Geometric (2xE tensor, where E is the number of edges)\n",
    "    edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "    \n",
    "    # Create a unique list of node and relation IDs\n",
    "    uniq_v = np.unique(np.concatenate([src, dst]))  # Unique nodes\n",
    "    uniq_r = np.unique(rel)  # Unique relations\n",
    "    \n",
    "    # Mapping of node and relation IDs\n",
    "    ids_map = {id_: idx for idx, id_ in enumerate(uniq_v)}\n",
    "    rel_map = {id_: idx for idx, id_ in enumerate(uniq_r)}\n",
    "\n",
    "    # Convert node and relation IDs to new indices (0 to N-1)\n",
    "    src = np.array([ids_map[i] for i in src], dtype=\"int64\")\n",
    "    dst = np.array([ids_map[i] for i in dst], dtype=\"int64\")\n",
    "    rel = np.array([rel_map[i] for i in rel], dtype=\"int64\")\n",
    "    \n",
    "    # Convert everything to PyTorch tensors\n",
    "    edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "    edge_rel = torch.tensor(rel, dtype=torch.long)\n",
    "\n",
    "    data = Data(edge_index=edge_index)\n",
    "\n",
    "    return data, src, dst, rel, len(uniq_v), len(uniq_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "025cf70e-7150-40af-b94e-a0db2e7cc033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the GNN for link prediction\n",
    "def train_gnn(model, data, src, dst, rel, optimizer, epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass: Predict target nodes given source nodes and relations\n",
    "        pred = model(data.edge_index, torch.tensor(src), torch.tensor(rel))\n",
    "        \n",
    "        # Cross entropy loss (multi-class classification)\n",
    "        loss = F.cross_entropy(pred, torch.tensor(dst))\n",
    "        \n",
    "        # Backpropagate and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52c45550-9b5f-4b54-aad9-654cc3b5c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of the GNN model\n",
    "def predictions(model, data, src, rel):\n",
    "    model.eval()\n",
    "    pred = model(data.edge_index, torch.tensor(src), torch.tensor(rel)).argmax(dim=1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37f12381-c161-4f69-909d-b0d17c588f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gnn(model, data, src, dst, rel):\n",
    "    model.eval()\n",
    "    \n",
    "    # Pass the data through the GNN model\n",
    "    with torch.no_grad():\n",
    "        pred = model(data.x, data.edge_index, rel)\n",
    "    \n",
    "    # Compute the prediction score using softmax to normalize outputs\n",
    "    pred_scores = F.softmax(pred, dim=-1)\n",
    "    \n",
    "    # Evaluate prediction using ranking metrics (MRR, Hits@K)\n",
    "    mrr = 0\n",
    "    hits_at_1 = 0\n",
    "    hits_at_3 = 0\n",
    "    hits_at_10 = 0\n",
    "    total_examples = len(src)\n",
    "    \n",
    "    for i in range(total_examples):\n",
    "        # Get the predicted scores for the specific source node and relation\n",
    "        target_scores = pred_scores[i]\n",
    "        \n",
    "        # Sort predicted scores in descending order\n",
    "        sorted_indices = torch.argsort(target_scores, descending=True)\n",
    "        \n",
    "        # Get the rank of the true target node\n",
    "        true_target = dst[i]\n",
    "        rank = (sorted_indices == true_target).nonzero(as_tuple=True)[0].item() + 1\n",
    "        \n",
    "        # Update MRR\n",
    "        mrr += 1.0 / rank\n",
    "        \n",
    "        # Update Hits@K (1, 3, 10)\n",
    "        if rank <= 1:\n",
    "            hits_at_1 += 1\n",
    "        if rank <= 3:\n",
    "            hits_at_3 += 1\n",
    "        if rank <= 10:\n",
    "            hits_at_10 += 1\n",
    "    \n",
    "    # Compute average metrics\n",
    "    mrr /= total_examples\n",
    "    hits_at_1 /= total_examples\n",
    "    hits_at_3 /= total_examples\n",
    "    hits_at_10 /= total_examples\n",
    "    \n",
    "    print(f\"MRR: {mrr:.4f}\")\n",
    "    print(f\"Hits@1: {hits_at_1:.4f}\")\n",
    "    print(f\"Hits@3: {hits_at_3:.4f}\")\n",
    "    print(f\"Hits@10: {hits_at_10:.4f}\")\n",
    "    \n",
    "    return mrr, hits_at_1, hits_at_3, hits_at_10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64e02678-c4dc-444c-815f-da5180d44b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\desai\\AppData\\Local\\Temp\\ipykernel_6316\\3209822001.py:27: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\b\\abs_6fueooay2f\\croot\\pytorch-select_1707342446212\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "  edge_index = torch.tensor([src, dst], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# folder_path = 'path_to_your_data_folder'\n",
    "data, src, dst, rel, num_nodes, num_relations = construct_graph(folder_path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d11235d-b6cb-48cf-93b8-14b7153ca613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model and optimizer\n",
    "embedding_dim = 16  # Embedding dimension for nodes and relations\n",
    "model = GNNLinkPredictor(num_nodes, num_relations, embedding_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d13a9e3f-5122-454f-b1f3-14001ef770e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 22.589685440063477\n",
      "Epoch 10, Loss: 18.773927688598633\n",
      "Epoch 20, Loss: 15.628406524658203\n",
      "Epoch 30, Loss: 13.071314811706543\n",
      "Epoch 40, Loss: 11.003024101257324\n",
      "Epoch 50, Loss: 9.3135404586792\n",
      "Epoch 60, Loss: 7.988504409790039\n",
      "Epoch 70, Loss: 6.993292331695557\n",
      "Epoch 80, Loss: 6.204977512359619\n",
      "Epoch 90, Loss: 5.607674598693848\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_gnn(model, data, src, dst, rel, optimizer, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bac60b0-c7a1-4184-a62f-050cfb14ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, src, dst, rel, num_nodes, num_relations = construct_graph(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42580a57-cadc-489d-9075-f62d45239104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Targets: tensor([   2,    2,    0,  ...,   38, 1999, 1436])\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "predictions = predictions(model, data, src, rel)\n",
    "print(f\"Predicted Targets: {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "043775f1-e63e-4a1e-b032-a6f77ca872c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mrr, hits_at_1, hits_at_3, hits_at_10 = evaluate_gnn(model, data, src, dst, rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "574fb0a4-55a3-41cd-a08b-cd514e36135e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Embeddings:  tensor([[-0.2982, -1.5854,  0.0246,  ...,  0.9065, -0.1636,  0.6877],\n",
      "        [ 0.0527, -0.3391, -0.5066,  ..., -0.0316, -0.8781,  1.0560],\n",
      "        [-0.1218,  0.0459, -0.5276,  ...,  1.1155,  0.6376,  1.3218],\n",
      "        ...,\n",
      "        [-1.3182, -0.1868, -0.4268,  ...,  0.5435, -0.1060, -0.7133],\n",
      "        [-0.6951, -0.3809, -0.7487,  ..., -1.4436,  0.5245, -0.8324],\n",
      "        [-1.7722, -0.5521,  1.4869,  ...,  1.2942,  0.5039, -1.1969]]) torch.Size([3214, 16])\n",
      "Relation Embeddings:  tensor([[ 0.1141, -0.1772,  0.7037,  ...,  0.0979, -0.7028,  0.5914],\n",
      "        [-0.3722,  0.0722, -1.3695,  ...,  0.0701,  0.2583,  0.7373],\n",
      "        [ 0.4945, -0.3587, -0.8339,  ..., -0.8798, -0.2030,  0.4242],\n",
      "        ...,\n",
      "        [ 0.2992,  0.0163, -0.0649,  ..., -1.0251, -0.7438,  0.3439],\n",
      "        [ 1.0390, -0.4406, -0.6457,  ..., -1.4726, -0.9166,  0.6888],\n",
      "        [ 1.3405,  0.0834, -0.5542,  ..., -0.5560, -1.5425, -0.4696]]) torch.Size([209, 16])\n"
     ]
    }
   ],
   "source": [
    "node_embeddings = model.node_embeddings.weight.data\n",
    "print(\"Node Embeddings: \", node_embeddings, node_embeddings.shape)\n",
    "\n",
    "relation_embeddings = model.rel_embeddings.weight.data\n",
    "print(\"Relation Embeddings: \", relation_embeddings, relation_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253565ad-5dd6-4a88-a104-9faccfb6876e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
